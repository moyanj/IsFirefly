import argparse
import os
import sys
import torch
from datetime import datetime


def load_model(model_path):
    """å®‰å…¨åŠ è½½PyTorchæ¨¡å‹æ–‡ä»¶"""
    try:
        if not os.path.isfile(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        model = torch.load(model_path, map_location="cpu")
        return model
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
        sys.exit(1)


def format_timestamp(timestamp):
    """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼"""
    try:
        return datetime.fromisoformat(timestamp).strftime("%Y-%m-%d %H:%M:%S")
    except:
        return "æœªçŸ¥æ—¶é—´"


def main():
    # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="PyTorchæ¨¡å‹æ£€æŸ¥ç‚¹åˆ†æå·¥å…·")
    parser.add_argument("model_path", type=str, help="æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    # åŠ è½½æ¨¡å‹
    model = load_model(args.model_path)

    # æ‰“å°åŸºç¡€ä¿¡æ¯
    print(f"\nğŸ” åˆ†ææ¨¡å‹: {os.path.basename(args.model_path)}")
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {os.path.abspath(args.model_path)}")
    print(f"ğŸ•’ ä¿å­˜æ—¶é—´: {format_timestamp(model.get('time', 0))}")
    print(f"ğŸ“ æ£€æŸ¥ç‚¹ç±»å‹: {model.get('type', 'æœªæŒ‡å®š')}")

    # æ£€æŸ¥å¯æ¢å¤è®­ç»ƒçŠ¶æ€
    required_keys = {"optimizer_state", "scheduler_state", "model_state"}
    missing_keys = required_keys - set(model.keys())
    resumable = len(missing_keys) == 0

    print(f"\nğŸ”„ å¯æ¢å¤è®­ç»ƒ: {'âœ… æ˜¯' if resumable else 'âŒ å¦'}")
    if not resumable and missing_keys:
        print(f"  ç¼ºå¤±å…³é”®çŠ¶æ€: {', '.join(missing_keys)}")

    # æ‰“å°è®­ç»ƒä¿¡æ¯
    print(f"\nğŸ“Š è®­ç»ƒä¿¡æ¯:")
    if "epoch" in model:
        print(f"  - å½“å‰è½®æ¬¡: {model['epoch']}")

    checkpoint_type = model.get("type", "")
    if checkpoint_type == "step":
        print(f"  - å…¨å±€æ­¥æ•°: {model.get('step', 'N/A')}")
        print(f"  - è®­ç»ƒæŸå¤±: {model.get('loss', 'N/A'):.6f}")
    elif checkpoint_type == "epoch":
        print(f"  - æµ‹è¯•æŸå¤±: {model.get('val_loss', 'N/A'):.6f}")
        print(f"  - æµ‹è¯•å‡†ç¡®ç‡: {model.get('val_accuracy', 'N/A'):.2f}%")
        print(f"  - æœ€ä½³å‡†ç¡®ç‡: {model.get('best_accuracy', 'N/A'):.2f}%")
        print(f"  - å…¨å±€æ­¥æ•°: {model.get('step', 'N/A')}")
        print(f"  - æœ€ç»ˆè½®æ¬¡: {'æ˜¯' if model.get('is_last', False) else 'å¦'}")

    if "args" in model:
        print("\nâš™ï¸ è®­ç»ƒå‚æ•°:")
        args = model["args"]
        print(f"  - è®­ç»ƒæ€»è½®æ¬¡: {args['epochs']}")
        print(f"  - æ‰¹æ¬¡å¤§å°: {args['batch_size']}")
        print(f"  - å­¦ä¹ ç‡: {args['lr']}")
        print(f"  - æ•°æ®åŠ è½½å·¥ä½œçº¿ç¨‹æ•°: {args['num_workers']}")
        print(f"  - å†»ç»“ä¸»å¹²ç½‘ç»œæƒé‡: {'æ˜¯' if args['freeze_backbone'] else 'å¦'}")
        print(f"  - åŸºç¡€æ¨¡å‹åç§°: {args['model_name']}")
        print(f"  - å¯ç”¨torch.compile()ä¼˜åŒ–: {'æ˜¯' if args['compile'] else 'å¦'}")
        print(
            f"  - æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”ï¼ˆæ­¥æ•°ï¼‰: {'æ˜¯' if args['checkpoint_interval'] else 'å¦'}"
        )


if __name__ == "__main__":
    main()
